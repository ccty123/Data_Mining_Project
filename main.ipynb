{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data load and overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/df_train.csv\")\n",
    "test = pd.read_csv(\"./data/df_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize univariate outliers\n",
    "plt.subplots(figsize=(18,6))\n",
    "plt.title(\"Outliers visualization\")\n",
    "df.boxplot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16045084"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16016176"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only keep trips that lasted less than 5900 seconds\n",
    "df = df[(df.trip_duration < 5900)]\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only keep trips that lasted less than 5900 seconds\n",
    "df = df[(df.trip_duration < 5900)]\n",
    "\n",
    "#Only keep trips with passengers\n",
    "df = df[(df.passenger_count > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove position outliers\n",
    "df = df[(df.pickup_longitude > -100)]\n",
    "df = df[(df.pickup_latitude < 50)]\n",
    "df = df[(df.dropoff_longitude < -70) & (df.dropoff_longitude > -80)]\n",
    "df = df[(df.dropoff_latitude < 50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 17:24:55</td>\n",
       "      <td>2016-03-14 17:32:30</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.96463</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>N</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
       "0  id2875421          2  2016-03-14 17:24:55  2016-03-14 17:32:30   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                1        -73.982155        40.767937          -73.96463   \n",
       "\n",
       "   dropoff_latitude store_and_fwd_flag  trip_duration  \n",
       "0         40.765602                  N            455  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encoding binary categorical features\n",
    "df = pd.concat([df, pd.get_dummies(df['store_and_fwd_flag'])], axis=1)\n",
    "test = pd.concat([test, pd.get_dummies(test['store_and_fwd_flag'])], axis=1)\n",
    "\n",
    "df.drop(['store_and_fwd_flag'], axis=1, inplace=True)\n",
    "\n",
    "df = pd.concat([df, pd.get_dummies(df['vendor_id'])], axis=1)\n",
    "test = pd.concat([test, pd.get_dummies(test['vendor_id'])], axis=1)\n",
    "\n",
    "df.drop(['vendor_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp/ipykernel_2372/3263461535.py:9: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  df['week'] = df.pickup_datetime.dt.week\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp/ipykernel_2372/3263461535.py:17: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  test['week'] = test.pickup_datetime.dt.week\n"
     ]
    }
   ],
   "source": [
    "#Datetyping the dates\n",
    "df['pickup_datetime'] = pd.to_datetime(df.pickup_datetime)\n",
    "test['pickup_datetime'] = pd.to_datetime(test.pickup_datetime)\n",
    "\n",
    "df.drop(['dropoff_datetime'], axis=1, inplace=True) #as we don't have this feature in the testset\n",
    "\n",
    "#Date features creations and deletions\n",
    "df['month'] = df.pickup_datetime.dt.month\n",
    "df['week'] = df.pickup_datetime.dt.week\n",
    "df['weekday'] = df.pickup_datetime.dt.weekday\n",
    "df['hour'] = df.pickup_datetime.dt.hour\n",
    "df['minute'] = df.pickup_datetime.dt.minute\n",
    "df['minute_oftheday'] = df['hour'] * 60 + df['minute']\n",
    "df.drop(['minute'], axis=1, inplace=True)\n",
    "\n",
    "test['month'] = test.pickup_datetime.dt.month\n",
    "test['week'] = test.pickup_datetime.dt.week\n",
    "test['weekday'] = test.pickup_datetime.dt.weekday\n",
    "test['hour'] = test.pickup_datetime.dt.hour\n",
    "test['minute'] = test.pickup_datetime.dt.minute\n",
    "test['minute_oftheday'] = test['hour'] * 60 + test['minute']\n",
    "test.drop(['minute'], axis=1, inplace=True)\n",
    "\n",
    "df.drop(['pickup_datetime'], axis=1, inplace=True)\n",
    "\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function aiming at calculating distances from coordinates\n",
    "def ft_haversine_distance(lat1, lng1, lat2, lng2):\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    AVG_EARTH_RADIUS = 6371 #km\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n",
    "    return h\n",
    "\n",
    "#Add distance feature\n",
    "df['distance'] = ft_haversine_distance(df['pickup_latitude'].values,\n",
    "                                                 df['pickup_longitude'].values, \n",
    "                                                 df['dropoff_latitude'].values,\n",
    "                                                 df['dropoff_longitude'].values)\n",
    "test['distance'] = ft_haversine_distance(test['pickup_latitude'].values, \n",
    "                                                test['pickup_longitude'].values, \n",
    "                                                test['dropoff_latitude'].values, \n",
    "                                                test['dropoff_longitude'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function aiming at calculating the direction\n",
    "def ft_degree(lat1, lng1, lat2, lng2):\n",
    "    AVG_EARTH_RADIUS = 6371 #km\n",
    "    lng_delta_rad = np.radians(lng2 - lng1)\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    y = np.sin(lng_delta_rad) * np.cos(lat2)\n",
    "    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n",
    "    return np.degrees(np.arctan2(y, x))\n",
    "\n",
    "#Add direction feature\n",
    "df['direction'] = ft_degree(df['pickup_latitude'].values,\n",
    "                                df['pickup_longitude'].values,\n",
    "                                df['dropoff_latitude'].values,\n",
    "                                df['dropoff_longitude'].values)\n",
    "test['direction'] = ft_degree(test['pickup_latitude'].values,\n",
    "                                  test['pickup_longitude'].values, \n",
    "                                  test['dropoff_latitude'].values,\n",
    "                                  test['dropoff_longitude'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26206902"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize distance outliers\n",
    "df.boxplot(column='distance', return_type='axes');\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26206902"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove distance outliers\n",
    "df = df[(df.distance < 200)]\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>N</th>\n",
       "      <th>Y</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute_oftheday</th>\n",
       "      <th>distance</th>\n",
       "      <th>direction</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.964630</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>455</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1044</td>\n",
       "      <td>1.498521</td>\n",
       "      <td>99.970196</td>\n",
       "      <td>11.856428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2377394</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.980415</td>\n",
       "      <td>40.738564</td>\n",
       "      <td>-73.999481</td>\n",
       "      <td>40.731152</td>\n",
       "      <td>663</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1.805507</td>\n",
       "      <td>-117.153768</td>\n",
       "      <td>9.803659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id3858529</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979027</td>\n",
       "      <td>40.763939</td>\n",
       "      <td>-74.005333</td>\n",
       "      <td>40.710087</td>\n",
       "      <td>2124</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>695</td>\n",
       "      <td>6.385098</td>\n",
       "      <td>-159.680165</td>\n",
       "      <td>10.822201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3504673</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.010040</td>\n",
       "      <td>40.719971</td>\n",
       "      <td>-74.012268</td>\n",
       "      <td>40.706718</td>\n",
       "      <td>429</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1172</td>\n",
       "      <td>1.485498</td>\n",
       "      <td>-172.737700</td>\n",
       "      <td>12.465721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id2181028</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.973053</td>\n",
       "      <td>40.793209</td>\n",
       "      <td>-73.972923</td>\n",
       "      <td>40.782520</td>\n",
       "      <td>435</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>810</td>\n",
       "      <td>1.188588</td>\n",
       "      <td>179.473585</td>\n",
       "      <td>9.836594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  passenger_count  pickup_longitude  pickup_latitude  \\\n",
       "0  id2875421                1        -73.982155        40.767937   \n",
       "1  id2377394                1        -73.980415        40.738564   \n",
       "2  id3858529                1        -73.979027        40.763939   \n",
       "3  id3504673                1        -74.010040        40.719971   \n",
       "4  id2181028                1        -73.973053        40.793209   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  trip_duration  N  Y  1  2  month  \\\n",
       "0         -73.964630         40.765602            455  1  0  0  1      3   \n",
       "1         -73.999481         40.731152            663  1  0  1  0      6   \n",
       "2         -74.005333         40.710087           2124  1  0  0  1      1   \n",
       "3         -74.012268         40.706718            429  1  0  0  1      4   \n",
       "4         -73.972923         40.782520            435  1  0  0  1      3   \n",
       "\n",
       "   week  weekday  hour  minute_oftheday  distance   direction      speed  \n",
       "0    11        0    17             1044  1.498521   99.970196  11.856428  \n",
       "1    23        6     0               43  1.805507 -117.153768   9.803659  \n",
       "2     3        1    11              695  6.385098 -159.680165  10.822201  \n",
       "3    14        2    19             1172  1.485498 -172.737700  12.465721  \n",
       "4    12        5    13              810  1.188588  179.473585   9.836594  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualize distance outliers\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create speed feature\n",
    "df['speed'] = df.distance * 3600 / df.trip_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize speed feature\n",
    "df.boxplot(column='speed', return_type='axes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove speed outliers\n",
    "df = df[(df.speed < 30)]\n",
    "df.drop(['speed'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>N</th>\n",
       "      <th>Y</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute_oftheday</th>\n",
       "      <th>distance</th>\n",
       "      <th>direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.388395e+06</td>\n",
       "      <td>1.388395e+06</td>\n",
       "      <td>1.388395e+06</td>\n",
       "      <td>1.388395e+06</td>\n",
       "      <td>1.388395e+06</td>\n",
       "      <td>1.388395e+06</td>\n",
       "      <td>1.388395e+06</td>\n",
       "      <td>1.388395e+06</td>\n",
       "      <td>1.388395e+06</td>\n",
       "      <td>1.388395e+06</td>\n",
       "      <td>1.388395e+06</td>\n",
       "      <td>1.388395e+06</td>\n",
       "      <td>1.388395e+06</td>\n",
       "      <td>1.388395e+06</td>\n",
       "      <td>1.388395e+06</td>\n",
       "      <td>1.388395e+06</td>\n",
       "      <td>1.388395e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.664511e+00</td>\n",
       "      <td>-7.397544e+01</td>\n",
       "      <td>4.075165e+01</td>\n",
       "      <td>-7.397505e+01</td>\n",
       "      <td>4.075169e+01</td>\n",
       "      <td>8.250716e+02</td>\n",
       "      <td>9.945995e-01</td>\n",
       "      <td>5.400480e-03</td>\n",
       "      <td>4.659474e-01</td>\n",
       "      <td>5.340526e-01</td>\n",
       "      <td>3.520865e+00</td>\n",
       "      <td>1.382013e+01</td>\n",
       "      <td>3.041081e+00</td>\n",
       "      <td>1.371302e+01</td>\n",
       "      <td>8.523762e+02</td>\n",
       "      <td>3.081797e+00</td>\n",
       "      <td>-1.575013e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.313706e+00</td>\n",
       "      <td>3.551229e-02</td>\n",
       "      <td>2.765982e-02</td>\n",
       "      <td>3.297707e-02</td>\n",
       "      <td>3.087944e-02</td>\n",
       "      <td>6.428504e+02</td>\n",
       "      <td>7.328928e-02</td>\n",
       "      <td>7.328928e-02</td>\n",
       "      <td>4.988393e-01</td>\n",
       "      <td>4.988393e-01</td>\n",
       "      <td>1.680635e+00</td>\n",
       "      <td>8.500028e+00</td>\n",
       "      <td>1.944793e+00</td>\n",
       "      <td>6.294446e+00</td>\n",
       "      <td>3.779763e+02</td>\n",
       "      <td>3.276822e+00</td>\n",
       "      <td>1.051399e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-7.948790e+01</td>\n",
       "      <td>3.602930e+01</td>\n",
       "      <td>-7.948790e+01</td>\n",
       "      <td>3.602930e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.799927e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-7.399204e+01</td>\n",
       "      <td>4.073785e+01</td>\n",
       "      <td>-7.399146e+01</td>\n",
       "      <td>4.073638e+01</td>\n",
       "      <td>3.970000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>1.209653e+00</td>\n",
       "      <td>-1.264802e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-7.398199e+01</td>\n",
       "      <td>4.075417e+01</td>\n",
       "      <td>-7.398026e+01</td>\n",
       "      <td>4.075441e+01</td>\n",
       "      <td>6.530000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>8.920000e+02</td>\n",
       "      <td>2.024030e+00</td>\n",
       "      <td>7.552413e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>-7.396822e+01</td>\n",
       "      <td>4.076822e+01</td>\n",
       "      <td>-7.396458e+01</td>\n",
       "      <td>4.076912e+01</td>\n",
       "      <td>1.050000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.166000e+03</td>\n",
       "      <td>3.601693e+00</td>\n",
       "      <td>5.447296e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>-7.051190e+01</td>\n",
       "      <td>4.391176e+01</td>\n",
       "      <td>-7.051190e+01</td>\n",
       "      <td>4.391176e+01</td>\n",
       "      <td>5.897000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>5.300000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>1.439000e+03</td>\n",
       "      <td>4.352663e+01</td>\n",
       "      <td>1.800000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "count     1.388395e+06      1.388395e+06     1.388395e+06       1.388395e+06   \n",
       "mean      1.664511e+00     -7.397544e+01     4.075165e+01      -7.397505e+01   \n",
       "std       1.313706e+00      3.551229e-02     2.765982e-02       3.297707e-02   \n",
       "min       1.000000e+00     -7.948790e+01     3.602930e+01      -7.948790e+01   \n",
       "25%       1.000000e+00     -7.399204e+01     4.073785e+01      -7.399146e+01   \n",
       "50%       1.000000e+00     -7.398199e+01     4.075417e+01      -7.398026e+01   \n",
       "75%       2.000000e+00     -7.396822e+01     4.076822e+01      -7.396458e+01   \n",
       "max       9.000000e+00     -7.051190e+01     4.391176e+01      -7.051190e+01   \n",
       "\n",
       "       dropoff_latitude  trip_duration             N             Y  \\\n",
       "count      1.388395e+06   1.388395e+06  1.388395e+06  1.388395e+06   \n",
       "mean       4.075169e+01   8.250716e+02  9.945995e-01  5.400480e-03   \n",
       "std        3.087944e-02   6.428504e+02  7.328928e-02  7.328928e-02   \n",
       "min        3.602930e+01   1.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%        4.073638e+01   3.970000e+02  1.000000e+00  0.000000e+00   \n",
       "50%        4.075441e+01   6.530000e+02  1.000000e+00  0.000000e+00   \n",
       "75%        4.076912e+01   1.050000e+03  1.000000e+00  0.000000e+00   \n",
       "max        4.391176e+01   5.897000e+03  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                  1             2         month          week       weekday  \\\n",
       "count  1.388395e+06  1.388395e+06  1.388395e+06  1.388395e+06  1.388395e+06   \n",
       "mean   4.659474e-01  5.340526e-01  3.520865e+00  1.382013e+01  3.041081e+00   \n",
       "std    4.988393e-01  4.988393e-01  1.680635e+00  8.500028e+00  1.944793e+00   \n",
       "min    0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  2.000000e+00  7.000000e+00  1.000000e+00   \n",
       "50%    0.000000e+00  1.000000e+00  4.000000e+00  1.300000e+01  3.000000e+00   \n",
       "75%    1.000000e+00  1.000000e+00  5.000000e+00  2.000000e+01  5.000000e+00   \n",
       "max    1.000000e+00  1.000000e+00  6.000000e+00  5.300000e+01  6.000000e+00   \n",
       "\n",
       "               hour  minute_oftheday      distance     direction  \n",
       "count  1.388395e+06     1.388395e+06  1.388395e+06  1.388395e+06  \n",
       "mean   1.371302e+01     8.523762e+02  3.081797e+00 -1.575013e+01  \n",
       "std    6.294446e+00     3.779763e+02  3.276822e+00  1.051399e+02  \n",
       "min    0.000000e+00     0.000000e+00  0.000000e+00 -1.799927e+02  \n",
       "25%    9.000000e+00     5.860000e+02  1.209653e+00 -1.264802e+02  \n",
       "50%    1.400000e+01     8.920000e+02  2.024030e+00  7.552413e+00  \n",
       "75%    1.900000e+01     1.166000e+03  3.601693e+00  5.447296e+01  \n",
       "max    2.300000e+01     1.439000e+03  4.352663e+01  1.800000e+02  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1388395, 16), (1388395,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the labeled data frame into two sets: features and target\n",
    "y = df[\"trip_duration\"]\n",
    "df.drop([\"trip_duration\"], axis=1, inplace=True)\n",
    "df.drop(['id'], axis=1, inplace=True)\n",
    "X = df\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1110716, 16), (1110716,), (277679, 16), (277679,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the labeled data frame into two sets to train then test the models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2345)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "E:\\Miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "E:\\Miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7464809677157271 0.7456702259553296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327.27356976999715\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "#Try GradientBoosting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb = GradientBoostingRegressor()\n",
    "gb.fit(X_train, y_train)\n",
    "print(gb.score(X_train, y_train), gb.score(X_test, y_test))\n",
    "print(np.sqrt(MSE(y_test, gb.predict(X_test))))\n",
    "    \n",
    "#Output\n",
    "    #0.7454771059776502 0.7443578507676307\n",
    "    #0.39291173774102295\n",
    "    #CPU times: user 3min 48s, sys: 328 ms, total: 3min 48s\n",
    "    #Wall time: 3min 48s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "E:\\Miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "E:\\Miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9738750467739886 0.8142258465132695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279.708057000626\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "#Try RandomForest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "print(rf.score(X_train, y_train), rf.score(X_test, y_test))\n",
    "print(np.sqrt(MSE(y_test, rf.predict(X_test))))\n",
    "\n",
    "#Output:\n",
    "    #0.9601197799928392 0.7790255381297454\n",
    "    #0.36530012047088345\n",
    "    #CPU times: user 3min, sys: 792 ms, total: 3min 1s\n",
    "    #Wall time: 3min 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Miniconda3\\envs\\myenv\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1866\n",
      "[LightGBM] [Info] Number of data points in the train set: 1164755, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 834.677624\n",
      "[1]\ttraining's rmse: 604.27\tvalid_1's rmse: 605.131\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\ttraining's rmse: 566.007\tvalid_1's rmse: 566.924\n",
      "[3]\ttraining's rmse: 532.762\tvalid_1's rmse: 533.767\n",
      "[4]\ttraining's rmse: 503.844\tvalid_1's rmse: 504.955\n",
      "[5]\ttraining's rmse: 479.024\tvalid_1's rmse: 480.189\n",
      "[6]\ttraining's rmse: 457.592\tvalid_1's rmse: 458.807\n",
      "[7]\ttraining's rmse: 439.255\tvalid_1's rmse: 440.479\n",
      "[8]\ttraining's rmse: 423.63\tvalid_1's rmse: 424.884\n",
      "[9]\ttraining's rmse: 410.255\tvalid_1's rmse: 411.502\n",
      "[10]\ttraining's rmse: 398.756\tvalid_1's rmse: 399.973\n",
      "[11]\ttraining's rmse: 389\tvalid_1's rmse: 390.203\n",
      "[12]\ttraining's rmse: 380.619\tvalid_1's rmse: 381.847\n",
      "[13]\ttraining's rmse: 373.495\tvalid_1's rmse: 374.729\n",
      "[14]\ttraining's rmse: 367.264\tvalid_1's rmse: 368.485\n",
      "[15]\ttraining's rmse: 361.56\tvalid_1's rmse: 362.741\n",
      "[16]\ttraining's rmse: 356.74\tvalid_1's rmse: 357.893\n",
      "[17]\ttraining's rmse: 352.625\tvalid_1's rmse: 353.759\n",
      "[18]\ttraining's rmse: 348.675\tvalid_1's rmse: 349.807\n",
      "[19]\ttraining's rmse: 345.265\tvalid_1's rmse: 346.395\n",
      "[20]\ttraining's rmse: 342.312\tvalid_1's rmse: 343.426\n",
      "[21]\ttraining's rmse: 339.735\tvalid_1's rmse: 340.861\n",
      "[22]\ttraining's rmse: 337.089\tvalid_1's rmse: 338.228\n",
      "[23]\ttraining's rmse: 334.912\tvalid_1's rmse: 336.053\n",
      "[24]\ttraining's rmse: 332.797\tvalid_1's rmse: 333.931\n",
      "[25]\ttraining's rmse: 330.983\tvalid_1's rmse: 332.123\n",
      "[26]\ttraining's rmse: 329.253\tvalid_1's rmse: 330.394\n",
      "[27]\ttraining's rmse: 327.666\tvalid_1's rmse: 328.786\n",
      "[28]\ttraining's rmse: 326.264\tvalid_1's rmse: 327.351\n",
      "[29]\ttraining's rmse: 324.632\tvalid_1's rmse: 325.707\n",
      "[30]\ttraining's rmse: 323.276\tvalid_1's rmse: 324.332\n",
      "[31]\ttraining's rmse: 321.996\tvalid_1's rmse: 323.048\n",
      "[32]\ttraining's rmse: 320.762\tvalid_1's rmse: 321.838\n",
      "[33]\ttraining's rmse: 319.62\tvalid_1's rmse: 320.687\n",
      "[34]\ttraining's rmse: 318.339\tvalid_1's rmse: 319.377\n",
      "[35]\ttraining's rmse: 317.437\tvalid_1's rmse: 318.463\n",
      "[36]\ttraining's rmse: 316.277\tvalid_1's rmse: 317.325\n",
      "[37]\ttraining's rmse: 315.47\tvalid_1's rmse: 316.56\n",
      "[38]\ttraining's rmse: 314.444\tvalid_1's rmse: 315.507\n",
      "[39]\ttraining's rmse: 313.588\tvalid_1's rmse: 314.639\n",
      "[40]\ttraining's rmse: 312.872\tvalid_1's rmse: 313.923\n",
      "[41]\ttraining's rmse: 312.124\tvalid_1's rmse: 313.183\n",
      "[42]\ttraining's rmse: 311.186\tvalid_1's rmse: 312.251\n",
      "[43]\ttraining's rmse: 310.4\tvalid_1's rmse: 311.493\n",
      "[44]\ttraining's rmse: 309.602\tvalid_1's rmse: 310.696\n",
      "[45]\ttraining's rmse: 308.734\tvalid_1's rmse: 309.819\n",
      "[46]\ttraining's rmse: 308.106\tvalid_1's rmse: 309.201\n",
      "[47]\ttraining's rmse: 307.325\tvalid_1's rmse: 308.449\n",
      "[48]\ttraining's rmse: 306.664\tvalid_1's rmse: 307.791\n",
      "[49]\ttraining's rmse: 306.102\tvalid_1's rmse: 307.227\n",
      "[50]\ttraining's rmse: 305.403\tvalid_1's rmse: 306.52\n",
      "[51]\ttraining's rmse: 304.775\tvalid_1's rmse: 305.886\n",
      "[52]\ttraining's rmse: 304.298\tvalid_1's rmse: 305.427\n",
      "[53]\ttraining's rmse: 303.745\tvalid_1's rmse: 304.872\n",
      "[54]\ttraining's rmse: 303.118\tvalid_1's rmse: 304.266\n",
      "[55]\ttraining's rmse: 302.643\tvalid_1's rmse: 303.794\n",
      "[56]\ttraining's rmse: 302.257\tvalid_1's rmse: 303.412\n",
      "[57]\ttraining's rmse: 301.91\tvalid_1's rmse: 303.07\n",
      "[58]\ttraining's rmse: 301.424\tvalid_1's rmse: 302.588\n",
      "[59]\ttraining's rmse: 300.942\tvalid_1's rmse: 302.107\n",
      "[60]\ttraining's rmse: 300.657\tvalid_1's rmse: 301.833\n",
      "[61]\ttraining's rmse: 300.268\tvalid_1's rmse: 301.449\n",
      "[62]\ttraining's rmse: 299.859\tvalid_1's rmse: 301.034\n",
      "[63]\ttraining's rmse: 299.532\tvalid_1's rmse: 300.711\n",
      "[64]\ttraining's rmse: 298.991\tvalid_1's rmse: 300.186\n",
      "[65]\ttraining's rmse: 298.591\tvalid_1's rmse: 299.783\n",
      "[66]\ttraining's rmse: 298.09\tvalid_1's rmse: 299.283\n",
      "[67]\ttraining's rmse: 297.742\tvalid_1's rmse: 298.943\n",
      "[68]\ttraining's rmse: 297.49\tvalid_1's rmse: 298.709\n",
      "[69]\ttraining's rmse: 297.019\tvalid_1's rmse: 298.262\n",
      "[70]\ttraining's rmse: 296.66\tvalid_1's rmse: 297.91\n",
      "[71]\ttraining's rmse: 296.312\tvalid_1's rmse: 297.575\n",
      "[72]\ttraining's rmse: 296.075\tvalid_1's rmse: 297.343\n",
      "[73]\ttraining's rmse: 295.733\tvalid_1's rmse: 297.017\n",
      "[74]\ttraining's rmse: 295.377\tvalid_1's rmse: 296.655\n",
      "[75]\ttraining's rmse: 295.155\tvalid_1's rmse: 296.44\n",
      "[76]\ttraining's rmse: 294.938\tvalid_1's rmse: 296.224\n",
      "[77]\ttraining's rmse: 294.81\tvalid_1's rmse: 296.1\n",
      "[78]\ttraining's rmse: 294.556\tvalid_1's rmse: 295.85\n",
      "[79]\ttraining's rmse: 294.293\tvalid_1's rmse: 295.598\n",
      "[80]\ttraining's rmse: 294.004\tvalid_1's rmse: 295.325\n",
      "[81]\ttraining's rmse: 293.67\tvalid_1's rmse: 295.01\n",
      "[82]\ttraining's rmse: 293.418\tvalid_1's rmse: 294.746\n",
      "[83]\ttraining's rmse: 293.319\tvalid_1's rmse: 294.655\n",
      "[84]\ttraining's rmse: 293.132\tvalid_1's rmse: 294.485\n",
      "[85]\ttraining's rmse: 292.805\tvalid_1's rmse: 294.162\n",
      "[86]\ttraining's rmse: 292.586\tvalid_1's rmse: 293.958\n",
      "[87]\ttraining's rmse: 292.324\tvalid_1's rmse: 293.701\n",
      "[88]\ttraining's rmse: 292.081\tvalid_1's rmse: 293.47\n",
      "[89]\ttraining's rmse: 291.996\tvalid_1's rmse: 293.392\n",
      "[90]\ttraining's rmse: 291.765\tvalid_1's rmse: 293.167\n",
      "[91]\ttraining's rmse: 291.595\tvalid_1's rmse: 293.021\n",
      "[92]\ttraining's rmse: 291.39\tvalid_1's rmse: 292.814\n",
      "[93]\ttraining's rmse: 291.277\tvalid_1's rmse: 292.698\n",
      "[94]\ttraining's rmse: 291.076\tvalid_1's rmse: 292.509\n",
      "[95]\ttraining's rmse: 290.867\tvalid_1's rmse: 292.3\n",
      "[96]\ttraining's rmse: 290.65\tvalid_1's rmse: 292.09\n",
      "[97]\ttraining's rmse: 290.467\tvalid_1's rmse: 291.919\n",
      "[98]\ttraining's rmse: 290.272\tvalid_1's rmse: 291.746\n",
      "[99]\ttraining's rmse: 290.106\tvalid_1's rmse: 291.575\n",
      "[100]\ttraining's rmse: 290.048\tvalid_1's rmse: 291.522\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 290.048\tvalid_1's rmse: 291.522\n",
      "0.7996393999601503 0.800029655023442\n",
      "290.1984769589081\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "#Try LightGBM ----------------------------\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_params = {\n",
    "   'metric': 'rmse',\n",
    "   'is_training_metric': True}\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_test = lgb.Dataset(X_test, y_test)\n",
    "lgb_model = lgb.train(lgb_params, lgb_train, num_boost_round=100, valid_sets=[lgb_train, lgb_test], early_stopping_rounds=5)\n",
    "\n",
    "#Output\n",
    "    #[100]\tvalid_0's rmse: 0.362209\tvalid_1's rmse: 0.3629\n",
    "    #CPU times: user 40.9 s, sys: 332 ms, total: 41.2 s\n",
    "    #Wall time: 21.2 s\n",
    "\n",
    "#Try LightGBM with sklearn API ------------\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgbm = lgb.LGBMRegressor()\n",
    "lgbm.fit(X, y)\n",
    "print(lgbm.score(X_train, y_train), lgbm.score(X_test, y_test))\n",
    "print(np.sqrt(MSE(y_test, lgbm.predict(X_test))))\n",
    "\n",
    "#Output:\n",
    "    #0.7812886118508641 0.7827256176145024\n",
    "    #0.3623481127815768\n",
    "    #CPU times: user 42 s, sys: 1.08 s, total: 43 s\n",
    "    #Wall time: 22.5 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1867\n",
      "[LightGBM] [Info] Number of data points in the train set: 1164752, number of used features: 16\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1867\n",
      "[LightGBM] [Info] Number of data points in the train set: 1164752, number of used features: 16\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1867\n",
      "[LightGBM] [Info] Number of data points in the train set: 1164752, number of used features: 16\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1867\n",
      "[LightGBM] [Info] Number of data points in the train set: 1164752, number of used features: 16\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1867\n",
      "[LightGBM] [Info] Number of data points in the train set: 1164752, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 834.755704\n",
      "[LightGBM] [Info] Start training from score 834.804072\n",
      "[LightGBM] [Info] Start training from score 834.492062\n",
      "[LightGBM] [Info] Start training from score 834.289728\n",
      "[LightGBM] [Info] Start training from score 835.013202\n",
      "[0.79729522 0.79790673 0.79888871 0.79945536 0.79841255]\n",
      "0.798391714192806\n"
     ]
    }
   ],
   "source": [
    "#Cross-validation on LightGBM model --------------------------\n",
    "lgb_df = lgb.Dataset(X, y)\n",
    "lgb.cv(lgb_params, lgb_df, stratified=False) #False is needed as it only works with classification\n",
    "\n",
    "#Cross-validation on LightGBM model (sklearn API) ------------\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_score = cross_val_score(lgbm, X, y, cv=5)\n",
    "print(cv_score)\n",
    "print(np.mean(cv_score))\n",
    "\n",
    "#Output:\n",
    "    #[0.77872018 0.7801329  0.77988107 0.78049745 0.77904688]\n",
    "    #0.7796556968369478"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters tuning using RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 5, stop = 20, num = 16)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators, 'max_features': max_features, 'max_depth': max_depth, 'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n",
    "\n",
    "random_cv = RandomizedSearchCV(estimator = m1, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "print(random_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Miniconda3\\envs\\myenv\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6999\n",
      "[LightGBM] [Info] Number of data points in the train set: 1164755, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 834.677624\n",
      "[1]\ttraining's l2: 358650\tvalid_1's l2: 359964\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\ttraining's l2: 311048\tvalid_1's l2: 312552\n",
      "[3]\ttraining's l2: 269759\tvalid_1's l2: 271414\n",
      "[4]\ttraining's l2: 235944\tvalid_1's l2: 237820\n",
      "[5]\ttraining's l2: 209764\tvalid_1's l2: 211779\n",
      "[6]\ttraining's l2: 186831\tvalid_1's l2: 189029\n",
      "[7]\ttraining's l2: 168002\tvalid_1's l2: 170419\n",
      "[8]\ttraining's l2: 153550\tvalid_1's l2: 156160\n",
      "[9]\ttraining's l2: 141631\tvalid_1's l2: 144396\n",
      "[10]\ttraining's l2: 130915\tvalid_1's l2: 133846\n",
      "[11]\ttraining's l2: 121834\tvalid_1's l2: 124929\n",
      "[12]\ttraining's l2: 114287\tvalid_1's l2: 117584\n",
      "[13]\ttraining's l2: 107982\tvalid_1's l2: 111475\n",
      "[14]\ttraining's l2: 103347\tvalid_1's l2: 106999\n",
      "[15]\ttraining's l2: 98706.7\tvalid_1's l2: 102545\n",
      "[16]\ttraining's l2: 94784.4\tvalid_1's l2: 98764.6\n",
      "[17]\ttraining's l2: 91441.6\tvalid_1's l2: 95592.6\n",
      "[18]\ttraining's l2: 88690.5\tvalid_1's l2: 93031.9\n",
      "[19]\ttraining's l2: 86322.5\tvalid_1's l2: 90823.4\n",
      "[20]\ttraining's l2: 84287\tvalid_1's l2: 88948.9\n",
      "[21]\ttraining's l2: 82578.7\tvalid_1's l2: 87411.8\n",
      "[22]\ttraining's l2: 81049.4\tvalid_1's l2: 86032.6\n",
      "[23]\ttraining's l2: 79744.2\tvalid_1's l2: 84883.7\n",
      "[24]\ttraining's l2: 78522.3\tvalid_1's l2: 83851.3\n",
      "[25]\ttraining's l2: 77472.4\tvalid_1's l2: 82971.9\n",
      "[26]\ttraining's l2: 76382.2\tvalid_1's l2: 82044.5\n",
      "[27]\ttraining's l2: 75298.1\tvalid_1's l2: 81108.7\n",
      "[28]\ttraining's l2: 74475.6\tvalid_1's l2: 80420.9\n",
      "[29]\ttraining's l2: 73734.3\tvalid_1's l2: 79824.2\n",
      "[30]\ttraining's l2: 72842.7\tvalid_1's l2: 79096.8\n",
      "[31]\ttraining's l2: 72171.9\tvalid_1's l2: 78575.9\n",
      "[32]\ttraining's l2: 71554.7\tvalid_1's l2: 78135.9\n",
      "[33]\ttraining's l2: 70883.7\tvalid_1's l2: 77594\n",
      "[34]\ttraining's l2: 70376.7\tvalid_1's l2: 77217.7\n",
      "[35]\ttraining's l2: 69754.8\tvalid_1's l2: 76733.2\n",
      "[36]\ttraining's l2: 69216.7\tvalid_1's l2: 76330\n",
      "[37]\ttraining's l2: 68696.1\tvalid_1's l2: 75930.3\n",
      "[38]\ttraining's l2: 68250.8\tvalid_1's l2: 75660.7\n",
      "[39]\ttraining's l2: 67722.9\tvalid_1's l2: 75257.7\n",
      "[40]\ttraining's l2: 67339.9\tvalid_1's l2: 75025.5\n",
      "[41]\ttraining's l2: 66868.7\tvalid_1's l2: 74679\n",
      "[42]\ttraining's l2: 66507.2\tvalid_1's l2: 74456.9\n",
      "[43]\ttraining's l2: 66154.6\tvalid_1's l2: 74267.3\n",
      "[44]\ttraining's l2: 65767.2\tvalid_1's l2: 74026.6\n",
      "[45]\ttraining's l2: 65352.7\tvalid_1's l2: 73725.2\n",
      "[46]\ttraining's l2: 64988.3\tvalid_1's l2: 73499.7\n",
      "[47]\ttraining's l2: 64696.1\tvalid_1's l2: 73341.1\n",
      "[48]\ttraining's l2: 64312.2\tvalid_1's l2: 73081.5\n",
      "[49]\ttraining's l2: 63880.1\tvalid_1's l2: 72776.7\n",
      "[50]\ttraining's l2: 63587.8\tvalid_1's l2: 72648.5\n",
      "[51]\ttraining's l2: 63190\tvalid_1's l2: 72386\n",
      "[52]\ttraining's l2: 62828.8\tvalid_1's l2: 72167.4\n",
      "[53]\ttraining's l2: 62473\tvalid_1's l2: 71916.1\n",
      "[54]\ttraining's l2: 62243.3\tvalid_1's l2: 71831.1\n",
      "[55]\ttraining's l2: 61938\tvalid_1's l2: 71648\n",
      "[56]\ttraining's l2: 61666.7\tvalid_1's l2: 71495.7\n",
      "[57]\ttraining's l2: 61264.9\tvalid_1's l2: 71200.6\n",
      "[58]\ttraining's l2: 61051\tvalid_1's l2: 71129.3\n",
      "[59]\ttraining's l2: 60835.2\tvalid_1's l2: 71076.5\n",
      "[60]\ttraining's l2: 60639.7\tvalid_1's l2: 71012.1\n",
      "[61]\ttraining's l2: 60255.4\tvalid_1's l2: 70756.9\n",
      "[62]\ttraining's l2: 59958.3\tvalid_1's l2: 70588.9\n",
      "[63]\ttraining's l2: 59682.5\tvalid_1's l2: 70436.4\n",
      "[64]\ttraining's l2: 59497.1\tvalid_1's l2: 70379.2\n",
      "[65]\ttraining's l2: 59225.8\tvalid_1's l2: 70232.7\n",
      "[66]\ttraining's l2: 58981\tvalid_1's l2: 70076\n",
      "[67]\ttraining's l2: 58708.4\tvalid_1's l2: 69913\n",
      "[68]\ttraining's l2: 58557.1\tvalid_1's l2: 69874.6\n",
      "[69]\ttraining's l2: 58305.2\tvalid_1's l2: 69729.7\n",
      "[70]\ttraining's l2: 58062.6\tvalid_1's l2: 69593.8\n",
      "[71]\ttraining's l2: 57833.4\tvalid_1's l2: 69474.5\n",
      "[72]\ttraining's l2: 57620\tvalid_1's l2: 69373.3\n",
      "[73]\ttraining's l2: 57463.9\tvalid_1's l2: 69348.9\n",
      "[74]\ttraining's l2: 57262.9\tvalid_1's l2: 69265.6\n",
      "[75]\ttraining's l2: 56980.5\tvalid_1's l2: 69107\n",
      "[76]\ttraining's l2: 56768.1\tvalid_1's l2: 68985.1\n",
      "[77]\ttraining's l2: 56627.5\tvalid_1's l2: 68974.8\n",
      "[78]\ttraining's l2: 56399.3\tvalid_1's l2: 68850.6\n",
      "[79]\ttraining's l2: 56187.8\tvalid_1's l2: 68731\n",
      "[80]\ttraining's l2: 56035.6\tvalid_1's l2: 68705.2\n",
      "[81]\ttraining's l2: 55865.7\tvalid_1's l2: 68635.5\n",
      "[82]\ttraining's l2: 55645\tvalid_1's l2: 68520.8\n",
      "[83]\ttraining's l2: 55502.9\tvalid_1's l2: 68467.4\n",
      "[84]\ttraining's l2: 55308.3\tvalid_1's l2: 68383.9\n",
      "[85]\ttraining's l2: 55142\tvalid_1's l2: 68328.7\n",
      "[86]\ttraining's l2: 54954.8\tvalid_1's l2: 68236\n",
      "[87]\ttraining's l2: 54779.9\tvalid_1's l2: 68161.4\n",
      "[88]\ttraining's l2: 54585.8\tvalid_1's l2: 68056.2\n",
      "[89]\ttraining's l2: 54423.7\tvalid_1's l2: 67979.8\n",
      "[90]\ttraining's l2: 54290\tvalid_1's l2: 67944.6\n",
      "[91]\ttraining's l2: 54150.1\tvalid_1's l2: 67904.7\n",
      "[92]\ttraining's l2: 54009.5\tvalid_1's l2: 67877.8\n",
      "[93]\ttraining's l2: 53863.4\tvalid_1's l2: 67843.1\n",
      "[94]\ttraining's l2: 53751.5\tvalid_1's l2: 67824.8\n",
      "[95]\ttraining's l2: 53621.6\tvalid_1's l2: 67780.3\n",
      "[96]\ttraining's l2: 53508.8\tvalid_1's l2: 67755.9\n",
      "[97]\ttraining's l2: 53389.8\tvalid_1's l2: 67751.2\n",
      "[98]\ttraining's l2: 53239.4\tvalid_1's l2: 67685.1\n",
      "[99]\ttraining's l2: 53080.2\tvalid_1's l2: 67621.7\n",
      "[100]\ttraining's l2: 52972.9\tvalid_1's l2: 67610.4\n",
      "[101]\ttraining's l2: 52856.2\tvalid_1's l2: 67594.5\n",
      "[102]\ttraining's l2: 52759.7\tvalid_1's l2: 67573.9\n",
      "[103]\ttraining's l2: 52654.9\tvalid_1's l2: 67562.4\n",
      "[104]\ttraining's l2: 52555.6\tvalid_1's l2: 67537.1\n",
      "[105]\ttraining's l2: 52381.1\tvalid_1's l2: 67455\n",
      "[106]\ttraining's l2: 52226.8\tvalid_1's l2: 67394.9\n",
      "[107]\ttraining's l2: 52074.5\tvalid_1's l2: 67326.9\n",
      "[108]\ttraining's l2: 51955.9\tvalid_1's l2: 67322.7\n",
      "[109]\ttraining's l2: 51824.1\tvalid_1's l2: 67303.5\n",
      "[110]\ttraining's l2: 51740.5\tvalid_1's l2: 67292.2\n",
      "[111]\ttraining's l2: 51648.6\tvalid_1's l2: 67268\n",
      "[112]\ttraining's l2: 51545.8\tvalid_1's l2: 67264.1\n",
      "[113]\ttraining's l2: 51458.1\tvalid_1's l2: 67252.9\n",
      "[114]\ttraining's l2: 51298.2\tvalid_1's l2: 67182.8\n",
      "[115]\ttraining's l2: 51205.2\tvalid_1's l2: 67163.9\n",
      "[116]\ttraining's l2: 51102.1\tvalid_1's l2: 67153.3\n",
      "[117]\ttraining's l2: 51021\tvalid_1's l2: 67144.3\n",
      "[118]\ttraining's l2: 50922.8\tvalid_1's l2: 67146\n",
      "[119]\ttraining's l2: 50835.9\tvalid_1's l2: 67125.8\n",
      "[120]\ttraining's l2: 50710.3\tvalid_1's l2: 67072\n",
      "[121]\ttraining's l2: 50630.8\tvalid_1's l2: 67059.6\n",
      "[122]\ttraining's l2: 50536.1\tvalid_1's l2: 67051.6\n",
      "[123]\ttraining's l2: 50399.6\tvalid_1's l2: 67002.6\n",
      "[124]\ttraining's l2: 50320.3\tvalid_1's l2: 67006.7\n",
      "[125]\ttraining's l2: 50234.1\tvalid_1's l2: 67005\n",
      "[126]\ttraining's l2: 50152.4\tvalid_1's l2: 66994.5\n",
      "[127]\ttraining's l2: 50052.9\tvalid_1's l2: 66970.6\n",
      "[128]\ttraining's l2: 49965.2\tvalid_1's l2: 66946.7\n",
      "[129]\ttraining's l2: 49857.9\tvalid_1's l2: 66913.5\n",
      "[130]\ttraining's l2: 49741.7\tvalid_1's l2: 66890.9\n",
      "[131]\ttraining's l2: 49643.4\tvalid_1's l2: 66874.3\n",
      "[132]\ttraining's l2: 49569\tvalid_1's l2: 66864\n",
      "[133]\ttraining's l2: 49486.9\tvalid_1's l2: 66851.4\n",
      "[134]\ttraining's l2: 49362.2\tvalid_1's l2: 66815\n",
      "[135]\ttraining's l2: 49286\tvalid_1's l2: 66809.9\n",
      "[136]\ttraining's l2: 49189.5\tvalid_1's l2: 66795.9\n",
      "[137]\ttraining's l2: 49118.4\tvalid_1's l2: 66786.5\n",
      "[138]\ttraining's l2: 49033.1\tvalid_1's l2: 66763.7\n",
      "[139]\ttraining's l2: 48946.8\tvalid_1's l2: 66754.9\n",
      "[140]\ttraining's l2: 48874.8\tvalid_1's l2: 66734.6\n",
      "[141]\ttraining's l2: 48794.9\tvalid_1's l2: 66727.6\n",
      "[142]\ttraining's l2: 48688.2\tvalid_1's l2: 66695.5\n",
      "[143]\ttraining's l2: 48622.7\tvalid_1's l2: 66685.8\n",
      "[144]\ttraining's l2: 48555.7\tvalid_1's l2: 66680.7\n",
      "[145]\ttraining's l2: 48492.1\tvalid_1's l2: 66677.7\n",
      "[146]\ttraining's l2: 48436.4\tvalid_1's l2: 66667.8\n",
      "[147]\ttraining's l2: 48352.7\tvalid_1's l2: 66654.1\n",
      "[148]\ttraining's l2: 48290.3\tvalid_1's l2: 66653.6\n",
      "[149]\ttraining's l2: 48210.9\tvalid_1's l2: 66646.4\n",
      "[150]\ttraining's l2: 48123.1\tvalid_1's l2: 66639.6\n",
      "[151]\ttraining's l2: 47982.8\tvalid_1's l2: 66601\n",
      "[152]\ttraining's l2: 47917.5\tvalid_1's l2: 66596\n",
      "[153]\ttraining's l2: 47836\tvalid_1's l2: 66581.1\n",
      "[154]\ttraining's l2: 47775.9\tvalid_1's l2: 66574\n",
      "[155]\ttraining's l2: 47709.5\tvalid_1's l2: 66562.2\n",
      "[156]\ttraining's l2: 47648.3\tvalid_1's l2: 66555.6\n",
      "[157]\ttraining's l2: 47532.7\tvalid_1's l2: 66523.8\n",
      "[158]\ttraining's l2: 47473.6\tvalid_1's l2: 66527.9\n",
      "[159]\ttraining's l2: 47379.1\tvalid_1's l2: 66503.3\n",
      "[160]\ttraining's l2: 47315.8\tvalid_1's l2: 66506.4\n",
      "[161]\ttraining's l2: 47212.5\tvalid_1's l2: 66478.4\n",
      "[162]\ttraining's l2: 47148.9\tvalid_1's l2: 66467.8\n",
      "[163]\ttraining's l2: 47083.5\tvalid_1's l2: 66469.7\n",
      "[164]\ttraining's l2: 47025.2\tvalid_1's l2: 66479\n",
      "[165]\ttraining's l2: 46946\tvalid_1's l2: 66459.2\n",
      "[166]\ttraining's l2: 46889.8\tvalid_1's l2: 66458.2\n",
      "[167]\ttraining's l2: 46814.3\tvalid_1's l2: 66444.9\n",
      "[168]\ttraining's l2: 46744.5\tvalid_1's l2: 66438.2\n",
      "[169]\ttraining's l2: 46687.3\tvalid_1's l2: 66430.6\n",
      "[170]\ttraining's l2: 46609.2\tvalid_1's l2: 66427.2\n",
      "[171]\ttraining's l2: 46553.2\tvalid_1's l2: 66432.3\n",
      "[172]\ttraining's l2: 46487.6\tvalid_1's l2: 66429.1\n",
      "[173]\ttraining's l2: 46419.1\tvalid_1's l2: 66417.8\n",
      "[174]\ttraining's l2: 46360.8\tvalid_1's l2: 66419.8\n",
      "[175]\ttraining's l2: 46281.2\tvalid_1's l2: 66396.9\n",
      "[176]\ttraining's l2: 46224.1\tvalid_1's l2: 66388.9\n",
      "[177]\ttraining's l2: 46101.7\tvalid_1's l2: 66346.4\n",
      "[178]\ttraining's l2: 46026.4\tvalid_1's l2: 66342.8\n",
      "[179]\ttraining's l2: 45959.3\tvalid_1's l2: 66334.8\n",
      "[180]\ttraining's l2: 45894\tvalid_1's l2: 66328.2\n",
      "[181]\ttraining's l2: 45809.1\tvalid_1's l2: 66288.3\n",
      "[182]\ttraining's l2: 45739.2\tvalid_1's l2: 66277\n",
      "[183]\ttraining's l2: 45631.9\tvalid_1's l2: 66236.9\n",
      "[184]\ttraining's l2: 45574.4\tvalid_1's l2: 66234\n",
      "[185]\ttraining's l2: 45516.4\tvalid_1's l2: 66231.4\n",
      "[186]\ttraining's l2: 45458\tvalid_1's l2: 66228.2\n",
      "[187]\ttraining's l2: 45392.4\tvalid_1's l2: 66221.5\n",
      "[188]\ttraining's l2: 45325.4\tvalid_1's l2: 66209.8\n",
      "[189]\ttraining's l2: 45241.9\tvalid_1's l2: 66193.8\n",
      "[190]\ttraining's l2: 45175.6\tvalid_1's l2: 66188.3\n",
      "[191]\ttraining's l2: 45103.4\tvalid_1's l2: 66166.2\n",
      "[192]\ttraining's l2: 45044.2\tvalid_1's l2: 66159.5\n",
      "[193]\ttraining's l2: 44994.8\tvalid_1's l2: 66155\n",
      "[194]\ttraining's l2: 44931.3\tvalid_1's l2: 66159.9\n",
      "[195]\ttraining's l2: 44860.3\tvalid_1's l2: 66134\n",
      "[196]\ttraining's l2: 44794.6\tvalid_1's l2: 66122\n",
      "[197]\ttraining's l2: 44722.9\tvalid_1's l2: 66109.2\n",
      "[198]\ttraining's l2: 44659\tvalid_1's l2: 66101.3\n",
      "[199]\ttraining's l2: 44606.3\tvalid_1's l2: 66095.9\n",
      "[200]\ttraining's l2: 44558\tvalid_1's l2: 66091.9\n",
      "[201]\ttraining's l2: 44502.1\tvalid_1's l2: 66086.9\n",
      "[202]\ttraining's l2: 44452.7\tvalid_1's l2: 66085\n",
      "[203]\ttraining's l2: 44368.9\tvalid_1's l2: 66061\n",
      "[204]\ttraining's l2: 44314.5\tvalid_1's l2: 66055.7\n",
      "[205]\ttraining's l2: 44239.1\tvalid_1's l2: 66033.2\n",
      "[206]\ttraining's l2: 44185.8\tvalid_1's l2: 66026.3\n",
      "[207]\ttraining's l2: 44125.8\tvalid_1's l2: 66026.1\n",
      "[208]\ttraining's l2: 44056.5\tvalid_1's l2: 66013.6\n",
      "[209]\ttraining's l2: 44007.1\tvalid_1's l2: 66018.4\n",
      "[210]\ttraining's l2: 43967.1\tvalid_1's l2: 66020.8\n",
      "[211]\ttraining's l2: 43904.5\tvalid_1's l2: 66012.8\n",
      "[212]\ttraining's l2: 43837\tvalid_1's l2: 65994.8\n",
      "[213]\ttraining's l2: 43785.8\tvalid_1's l2: 65992.1\n",
      "[214]\ttraining's l2: 43707\tvalid_1's l2: 65980.4\n",
      "[215]\ttraining's l2: 43657.4\tvalid_1's l2: 65983.7\n",
      "[216]\ttraining's l2: 43604\tvalid_1's l2: 65988.5\n",
      "[217]\ttraining's l2: 43522.3\tvalid_1's l2: 65962\n",
      "[218]\ttraining's l2: 43469.7\tvalid_1's l2: 65953.4\n",
      "[219]\ttraining's l2: 43429.3\tvalid_1's l2: 65954.4\n",
      "[220]\ttraining's l2: 43385.5\tvalid_1's l2: 65952.1\n",
      "[221]\ttraining's l2: 43302\tvalid_1's l2: 65951\n",
      "[222]\ttraining's l2: 43237\tvalid_1's l2: 65939.2\n",
      "[223]\ttraining's l2: 43186.3\tvalid_1's l2: 65938.7\n",
      "[224]\ttraining's l2: 43128.6\tvalid_1's l2: 65929.8\n",
      "[225]\ttraining's l2: 43085.5\tvalid_1's l2: 65929.5\n",
      "[226]\ttraining's l2: 43022.7\tvalid_1's l2: 65913\n",
      "[227]\ttraining's l2: 42947.1\tvalid_1's l2: 65900.6\n",
      "[228]\ttraining's l2: 42894.1\tvalid_1's l2: 65904\n",
      "[229]\ttraining's l2: 42838.6\tvalid_1's l2: 65895.9\n",
      "[230]\ttraining's l2: 42789.7\tvalid_1's l2: 65897.9\n",
      "[231]\ttraining's l2: 42744.8\tvalid_1's l2: 65893.9\n",
      "[232]\ttraining's l2: 42671.3\tvalid_1's l2: 65874.8\n",
      "[233]\ttraining's l2: 42621.6\tvalid_1's l2: 65867.5\n",
      "[234]\ttraining's l2: 42554.6\tvalid_1's l2: 65856.4\n",
      "[235]\ttraining's l2: 42511\tvalid_1's l2: 65858.8\n",
      "[236]\ttraining's l2: 42466\tvalid_1's l2: 65853.2\n",
      "[237]\ttraining's l2: 42410.6\tvalid_1's l2: 65848.7\n",
      "[238]\ttraining's l2: 42368.7\tvalid_1's l2: 65854.3\n",
      "[239]\ttraining's l2: 42318.6\tvalid_1's l2: 65852.4\n",
      "[240]\ttraining's l2: 42267.1\tvalid_1's l2: 65845.9\n",
      "[241]\ttraining's l2: 42218.5\tvalid_1's l2: 65838\n",
      "[242]\ttraining's l2: 42175\tvalid_1's l2: 65831.3\n",
      "[243]\ttraining's l2: 42086.4\tvalid_1's l2: 65802.3\n",
      "[244]\ttraining's l2: 42046.1\tvalid_1's l2: 65796.4\n",
      "[245]\ttraining's l2: 42000.9\tvalid_1's l2: 65795.9\n",
      "[246]\ttraining's l2: 41953.9\tvalid_1's l2: 65800\n",
      "[247]\ttraining's l2: 41912.2\tvalid_1's l2: 65796.9\n",
      "[248]\ttraining's l2: 41847\tvalid_1's l2: 65784.3\n",
      "[249]\ttraining's l2: 41800\tvalid_1's l2: 65784.9\n",
      "[250]\ttraining's l2: 41757.5\tvalid_1's l2: 65782.2\n",
      "[251]\ttraining's l2: 41709.7\tvalid_1's l2: 65786.6\n",
      "[252]\ttraining's l2: 41669.1\tvalid_1's l2: 65781.5\n",
      "[253]\ttraining's l2: 41620\tvalid_1's l2: 65776.1\n",
      "[254]\ttraining's l2: 41550.2\tvalid_1's l2: 65769.1\n",
      "[255]\ttraining's l2: 41499\tvalid_1's l2: 65766.7\n",
      "[256]\ttraining's l2: 41458.1\tvalid_1's l2: 65767.6\n",
      "[257]\ttraining's l2: 41413.5\tvalid_1's l2: 65771.4\n",
      "[258]\ttraining's l2: 41368.4\tvalid_1's l2: 65776.1\n",
      "[259]\ttraining's l2: 41317.7\tvalid_1's l2: 65781.7\n",
      "[260]\ttraining's l2: 41275.1\tvalid_1's l2: 65768.9\n",
      "Early stopping, best iteration is:\n",
      "[255]\ttraining's l2: 41499\tvalid_1's l2: 65766.7\n"
     ]
    }
   ],
   "source": [
    "#Test the following parameters\n",
    "lgb_params = {\n",
    "    'metric' : 'rmse',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 25,\n",
    "    'num_leaves': 1000, \n",
    "    'objective': 'regression',\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'max_bin': 1000 }\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_test = lgb.Dataset(X_test, y_test)\n",
    "lgb_model = lgb.train(lgb_params, lgb_train, num_boost_round=1500, valid_sets=[lgb_train, lgb_test], early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=90, min_samples_leaf=10, min_samples_split=15,\n",
       "                      n_estimators=300)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%time\n",
    "#Training on all labeled data using the best parameters in hyperparameters tuning\n",
    "rf = RandomForestRegressor(n_estimators=300, min_samples_leaf=10, min_samples_split=15, max_features='auto', max_depth=90, bootstrap=True)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(max_depth=25, n_estimators=500, num_leaves=1000,\n",
       "              objective='regression')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%time\n",
    "#Training on all labeled data using the best parameters (sklearn API version)\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgbm = lgb.LGBMRegressor(n_estimators=500, num_leaves=1000, max_depth=25, objective='regression')\n",
    "lgbm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7006\n",
      "[LightGBM] [Info] Number of data points in the train set: 1455944, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 834.670109\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Training on all labeled data using the best parameters\n",
    "lgb_df = lgb.Dataset(X, y)\n",
    "lgb_model = lgb.train(lgb_params, lgb_df, num_boost_round=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions on test data frame\n",
    "test_columns = X.columns\n",
    "predictions = lgb_model.predict(test[test_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 718.62445889,  822.46375252,  489.44081966, ..., 1839.52794045,\n",
       "       2182.7457362 , 1141.86572916])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.71828183])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id3004672</td>\n",
       "      <td>718.624459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id3505355</td>\n",
       "      <td>822.463753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id1217141</td>\n",
       "      <td>489.440820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id2150126</td>\n",
       "      <td>1130.830400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id1598245</td>\n",
       "      <td>391.433988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  trip_duration\n",
       "0  id3004672     718.624459\n",
       "1  id3505355     822.463753\n",
       "2  id1217141     489.440820\n",
       "3  id2150126    1130.830400\n",
       "4  id1598245     391.433988"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a data frame designed a submission on Kaggle\n",
    "submission = pd.DataFrame({'id': test.id, 'trip_duration': predictions})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a csv out of the submission data frame\n",
    "submission.to_csv(\"sub.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "217de8b50e573c8b8802e0bbb715946bec344194a791357bcf50b9654172d047"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('myenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
